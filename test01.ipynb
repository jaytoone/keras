{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = np.arange(10).reshape(-1, 1).astype('float32')\n",
    "data_Y = np.arange(10).reshape(-1, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n",
      "(3, 1)\n",
      "[[9.]\n",
      " [1.]\n",
      " [6.]\n",
      " [7.]\n",
      " [3.]\n",
      " [0.]\n",
      " [5.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split\\\n",
    "(data_X, data_Y, test_size=0.3, random_state=0)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, activations, initializers, \\\n",
    "losses, optimizers, metrics\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() \n",
    "\n",
    "model.add(layers.Dense(input_dim=1, units=128, activation=None)) \n",
    "# model.add(layers.BatchNormalization()) # Use this line as if needed\n",
    "model.add(layers.Activation('relu')) # layers.ELU or layers.LeakyReLU\n",
    "\n",
    "model.add(layers.Dense(units=128, activation=None)) \n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(units=64, activation=None)) \n",
    "model.add(layers.Activation('relu'))\n",
    "# model.add(layers.Dropout(rate=0.4))\n",
    "\n",
    "model.add(layers.Dense(units=1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss=losses.mean_squared_error,\n",
    "              metrics=[metrics.mean_squared_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/sample - loss: 1.0035 - mean_squared_error: 1.0035\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 570us/sample - loss: 0.0532 - mean_squared_error: 0.0532\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 570us/sample - loss: 0.1304 - mean_squared_error: 0.1304\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 135us/sample - loss: 0.7593 - mean_squared_error: 0.7593\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/sample - loss: 1.2219 - mean_squared_error: 1.2219\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_Y, batch_size=6, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 27ms/sample - loss: 0.9956 - mean_squared_error: 0.9956\n",
      "loss (mse) : 0.9955857396125793\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_X, test_Y)\n",
    "\n",
    "print('loss (mse) :', result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = np.array([11, 12, 13]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.9005575],\n",
       "       [14.055028 ],\n",
       "       [15.2095   ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pred_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = np.arange(10).reshape(-1, 1)\n",
    "# .astype('float32')\n",
    "data_Y = to_categorical([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split\\\n",
    "(data_X, data_Y, test_size=0.3, random_state=0)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() \n",
    "\n",
    "model.add(layers.Dense(input_dim=1, units=64, activation=None)) \n",
    "# model.add(layers.BatchNormalization()) # Use this line as if needed\n",
    "model.add(layers.Activation('relu')) # layers.ELU or layers.LeakyReLU\n",
    "\n",
    "model.add(layers.Dense(units=128, activation=None)) \n",
    "model.add(layers.Activation('relu')) \n",
    "\n",
    "model.add(layers.Dense(units=64, activation=None)) \n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(units=2, activation='softmax')) # One-hot vector for 0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(), \n",
    "              loss=tf.losses.sigmoid_cross_entropy,\n",
    "              metrics=[metrics.binary_accuracy]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s 0s/sample - loss: -1.2402 - binary_accuracy: 0.1429\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 0s/sample - loss: -1.2402 - binary_accuracy: 0.1429\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 427us/sample - loss: -1.2402 - binary_accuracy: 0.1429\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 427us/sample - loss: -1.2402 - binary_accuracy: 0.1429\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 427us/sample - loss: -1.2402 - binary_accuracy: 0.1429\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 35us/sample - loss: -1.2402 - binary_accuracy: 0.1429\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 318us/sample - loss: -1.2402 - binary_accuracy: 0.1429\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 637us/sample - loss: -1.2402 - binary_accuracy: 0.1429\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 570us/sample - loss: -1.2402 - binary_accuracy: 0.1429\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 570us/sample - loss: -1.2402 - binary_accuracy: 0.1429\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_Y, batch_size=6, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/sample - loss: -1.3593 - binary_accuracy: 0.0000e+00\n",
      "loss (cross-entropy) : -1.359256386756897\n",
      "test accuracy : 0.0\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_X, test_Y)\n",
    "\n",
    "print('loss (cross-entropy) :', result[0])\n",
    "print('test accuracy :', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = np.array([11, 12, 13]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(test_X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "data_X = np.arange(10).reshape(-1, 1).astype('float32')\n",
    "data_Y = np.array([1, 2, 3, 4, 5, 1, 2, 3, 4, 5]).astype('float32')\n",
    "data_Y = np_utils.to_categorical(data_Y, 6)\n",
    "print(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split\\\n",
    "(data_X, data_Y, test_size=0.3, random_state=0)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)\n",
    "print(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() \n",
    "\n",
    "model.add(layers.Dense(input_dim=1, units=64, activation=None)) \n",
    "# model.add(layers.BatchNormalization()) # Use this line as if needed\n",
    "model.add(layers.Activation('relu')) # layers.ELU or layers.LeakyReLU\n",
    "\n",
    "model.add(layers.Dense(units=64, activation=None)) \n",
    "model.add(layers.Activation('relu')) \n",
    "\n",
    "model.add(layers.Dense(units=32, activation=None)) \n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(units=6, activation='softmax')) # One-hot vector for 0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[metrics.categorical_accuracy]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_Y, batch_size=3, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_X, test_Y)\n",
    "\n",
    "print('loss (cross-entropy) :', result[0])\n",
    "print('test accuracy :', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = np.array([11, 12, 13]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(test_X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

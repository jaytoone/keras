{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\student\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = np.arange(10).reshape(-1, 1).astype('float32')\n",
    "data_Y = np.arange(10).reshape(-1, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n",
      "(3, 1)\n",
      "[[9.]\n",
      " [1.]\n",
      " [6.]\n",
      " [7.]\n",
      " [3.]\n",
      " [0.]\n",
      " [5.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split\\\n",
    "(data_X, data_Y, test_size=0.3, random_state=0)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, activations, initializers, \\\n",
    "losses, optimizers, metrics\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() \n",
    "\n",
    "model.add(layers.Dense(input_dim=1, units=64, activation=None)) \n",
    "# model.add(layers.BatchNormalization()) # Use this line as if needed\n",
    "model.add(layers.Activation('elu')) # layers.ELU or layers.LeakyReLU\n",
    "\n",
    "model.add(layers.Dense(units=64, activation=None)) \n",
    "model.add(layers.Activation('elu'))\n",
    "\n",
    "model.add(layers.Dense(units=64, activation=None)) \n",
    "model.add(layers.Activation('elu'))\n",
    "# model.add(layers.Dropout(rate=0.4))\n",
    "\n",
    "model.add(layers.Dense(units=1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss=losses.mean_squared_error,\n",
    "              metrics=[metrics.mean_squared_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_Y, batch_size=3, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 49ms/sample - loss: 1.6074 - mean_squared_error: 1.6074\n",
      "loss (mse) : 1.6074117422103882\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_X, test_Y)\n",
    "\n",
    "print('loss (mse) :', result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = np.array([11, 12, 13]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.959771],\n",
       "       [10.438289],\n",
       "       [10.897999]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pred_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n",
      "(3, 1)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "data_X = np.arange(10).reshape(-1, 1)\n",
    "# .astype('float32')\n",
    "data_Y = to_categorical([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split\\\n",
    "(data_X, data_Y, test_size=0.3, random_state=0)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() \n",
    "\n",
    "model.add(layers.Dense(input_dim=1, units=64, activation=None)) \n",
    "# model.add(layers.BatchNormalization()) # Use this line as if needed\n",
    "model.add(layers.Activation('elu')) # layers.ELU or layers.LeakyReLU\n",
    "\n",
    "model.add(layers.Dense(units=64, activation=None)) \n",
    "model.add(layers.Activation('elu')) \n",
    "\n",
    "model.add(layers.Dense(units=32, activation=None)) \n",
    "model.add(layers.Activation('elu'))\n",
    "\n",
    "model.add(layers.Dense(units=2, activation='softmax')) # One-hot vector for 0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(), \n",
    "              loss=tf.losses.sigmoid_cross_entropy,\n",
    "              metrics=[metrics.binary_accuracy]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_Y, batch_size=3, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 61ms/sample - loss: 0.7964 - binary_accuracy: 0.6667\n",
      "loss (cross-entropy) : 0.7963861227035522\n",
      "test accuracy : 0.6666667\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_X, test_Y)\n",
    "\n",
    "print('loss (cross-entropy) :', result[0])\n",
    "print('test accuracy :', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = np.array([11, 12, 13]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(test_X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "data_X = np.arange(10).reshape(-1, 1)\n",
    "data_Y = np.array([1, 2, 3, 4, 5, 1, 2, 3, 4, 5]).astype('float32')\n",
    "data_Y = np_utils.to_categorical(data_Y, 6)\n",
    "print(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n",
      "(3, 1)\n",
      "(3, 6)\n",
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = model_selection.train_test_split\\\n",
    "(data_X, data_Y, test_size=0.3, random_state=0)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)\n",
    "print(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() \n",
    "\n",
    "model.add(layers.Dense(input_dim=1, units=64, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "# model.add(layers.BatchNormalization()) # Use this line as if needed\n",
    "model.add(layers.Activation('elu')) # layers.ELU or layers.LeakyReLU\n",
    "\n",
    "model.add(layers.Dense(units=64, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "model.add(layers.Activation('elu')) \n",
    "\n",
    "model.add(layers.Dense(units=32, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "model.add(layers.Activation('elu'))\n",
    "\n",
    "model.add(layers.Dense(units=6, activation='softmax')) # One-hot vector for 0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[metrics.categorical_accuracy]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_Y, batch_size=3, epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 50ms/sample - loss: 2.8732 - categorical_accuracy: 0.3333\n",
      "loss (cross-entropy) : 2.873156785964966\n",
      "test accuracy : 0.33333334\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_X, test_Y)\n",
    "\n",
    "print('loss (cross-entropy) :', result[0])\n",
    "print('test accuracy :', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X = np.array([11, 12, 13]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(test_X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
